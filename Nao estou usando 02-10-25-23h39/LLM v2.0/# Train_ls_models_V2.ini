# Train_ls_models_V2


> ✅ **1. Dois modelos distintos**:  
> - **Modelo LS15++**: otimizado para acertar os **15 números exatos** (com loss focada em top-15).  
> - **Modelo LS14++**: otimizado para acertar **pelo menos 14 números** (com ênfase em repetição e recall de positivos).  
>
> ✅ **2. Atualização contínua**:  
> - Receber novos sorteios até **6x/semana** → precisa de **re-treinamento rápido, robusto e automatizável**.

---

## 🔧 **Principais problemas atuais**

1. **Funções duplicadas**: `fetch_history`, `to_binary`, `build_dataset_*` estão definidas **dentro do mesmo arquivo**, mas também são importadas de `utils_ls_models` e `build_models` → conflito e manutenção difícil.
2. **Modelos LS15 e LS14 básicos não são usados** — você já tem versões `pp` (plus-plus) mais avançadas.
3. **Falta de padronização** no treinamento: LS14pp usa `class_weight`, LS15pp usa `loss customizada + callback de métricas`.
4. **Não há suporte nativo para re-treinamento incremental** (ex: rodar diariamente via cron).
5. **Salvamento apenas em `.keras`** — ideal ter **SavedModel também** para compatibilidade.

---

## ✅ **Proposta de melhoria: 5 ações práticas**

### **1. Elimine duplicações — use um único módulo de dados**
Remova as funções `fetch_history`, `to_binary`, `build_dataset_*` do arquivo principal.  
**Mantenha apenas os imports**:

```python
from utils_ls_models import fetch_history, to_binary
from build_datasets import build_dataset_ls15pp, build_dataset_ls14pp  # crie este módulo
from build_models import build_lstm_ls15pp, build_lstm_ls14pp_hybrid
```

> 💡 Crie um arquivo `build_datasets.py` com todas as funções de construção de dataset. Isso evita conflitos e facilita manutenção.

---

### **2. Padronize o treinamento com callbacks robustos para AMBOS os modelos**

Use o **mesmo padrão** para os dois modelos:

- **LS15++**: otimiza **acerto médio de 15 números** → use `LoteriaMetricsCallback(k=15)`.
- **LS14++**: otimiza **frequência de ≥14 acertos** → use `LoteriaMetricsCallback(k=14)` + **loss com `pos_weight` alto**.

#### Exemplo de treino padronizado:
```python
def train_model(
    model_name: str,      # "ls15pp" ou "ls14pp"
    last_n=1000,
    window=50,
    epochs=100,
    batch=32,
    out_dir="./models"
):
    # 1. Carregar dados
    if model_name == "ls14pp":
        rows, rep_map = fetch_history(last_n=last_n, include_repeats=True)
        X, y = build_dataset_ls14pp(rows, rep_map, window)
        model = build_lstm_ls14pp_hybrid((window, 25), pos_weight=3.0)
        loss = weighted_bce(pos_weight=3.0)  # ou use class_weight
        k_target = 14
    else:  # ls15pp
        rows = fetch_history(last_n=last_n)
        X, y = build_dataset_ls15pp(rows, window)
        model = build_lstm_ls15pp((window, 25))
        loss = bce_with_topk_proxy(k=15, alpha=1.0)
        k_target = 15

    model.compile(optimizer=Adam(1e-3), loss=loss)

    # 2. Split
    (X_train, y_train), (X_val, y_val) = train_val_split(X, y)

    # 3. Callbacks
    base_name = f"modelo_{model_name}"
    best_loss_path = os.path.join(out_dir, f"{base_name}_bestloss.keras")
    best_hits_path = os.path.join(out_dir, f"{base_name}_besthits.keras")

    callbacks = [
        ModelCheckpoint(best_loss_path, monitor="val_loss", save_best_only=True),
        LoteriaMetricsCallback(
            val_data=(X_val, y_val),
            k=k_target,
            save_best_path=best_hits_path,
            verbose=1
        ),
        EarlyStopping(patience=10, restore_best_weights=True),
        ReduceLROnPlateau(patience=5, factor=0.5)
    ]

    # 4. Treinar
    model.fit(X_train, y_train, validation_data=(X_val, y_val), ...)

    # 5. Salvar em DOIS formatos
    model.save(best_hits_path)  # .keras
    model.export(best_hits_path.replace(".keras", "_saved"))  # SavedModel (Keras 3+)

    return model
```

---

### **3. Adicione suporte a re-treinamento automático (6x/semana)**

Crie um **script separado** ou **função `retrain_if_new_data()`**:

```python
def retrain_if_new_data(model_name: str, min_new_draws=1):
    """
    Verifica se há novos sorteios desde o último treino.
    Se sim, re-treina o modelo.
    """
    last_concurso_db = get_last_concurso_from_db()  # nova função em db_utils
    last_concurso_model = get_last_concurso_from_model_metadata(model_name)  # salve isso no treino!

    if last_concurso_db > last_concurso_model + min_new_draws:
        logging.info(f"Novos sorteios detectados! Re-treinando {model_name}...")
        train_model(model_name, last_n=1500, window=50, out_dir="./models")
    else:
        logging.info("Nenhum novo sorteio relevante. Pulando re-treino.")
```

> 🕒 **Agende com cron (Linux) ou Task Scheduler (Windows)** para rodar **6x/semana**:
> ```bash
> # Ex: rodar às 2h da manhã, seg a sáb
> 0 2 * * 1-6 cd /seu/projeto && python retrain_scheduler.py --models ls15pp ls14pp
> ```

---

### **4. Salve metadados junto com o modelo**

Ao treinar, salve um arquivo `metadata.json` com:
```json
{
  "model_name": "ls15pp",
  "last_concurso_trained": 3000,
  "last_n": 1500,
  "window": 50,
  "mean_hits_val": 11.2,
  "date_trained": "2024-06-10T10:30:00Z"
}
```

Isso permite:
- Saber **até que sorteio o modelo foi treinado**.
- Evitar re-treinar sem necessidade.
- Comparar versões.

---

### **5. Mantenha compatibilidade com seus scripts existentes**

Seus outros arquivos (`train_ls_models_v1_and_auto_retrain_updates.py`, `train_ls_models_advanced.py`) devem poder:
- **Carregar os modelos salvos** (`.keras` ou `_saved`).
- **Usar as mesmas funções de `utils_ls_models` e `build_datasets`**.

✅ **Solução**:  
- Mantenha **todos os utilitários em módulos separados** (`utils_ls_models.py`, `build_datasets.py`, `build_models.py`).
- Seus scripts de treino **só devem conter lógica de treino**, não definições de funções.

---

## 📁 Estrutura final recomendada

```
projeto/
├── train_llm_loteria.py          ← só treino + CLI
├── retrain_scheduler.py          ← checa novos sorteios e re-treina
├── utils_ls_models.py            ← fetch_history, to_binary
├── build_datasets.py             ← build_dataset_ls15pp, build_dataset_ls14pp
├── build_models.py               ← build_lstm_ls15pp, build_lstm_ls14pp_hybrid
├── db.py                         ← Session
├── models/                       ← modelos salvos (.keras + _saved)
│   ├── modelo_ls15pp_besthits.keras
│   ├── modelo_ls15pp_besthits_saved/
│   ├── modelo_ls14pp_besthits.keras
│   └── ...
└── backtest/                     ← para testes históricos
```

---

## ✅ Benefícios dessa abordagem

| Benefício | Como é resolvido |
|--------|------------------|
| **Dois modelos distintos** | LS15pp (top-15) e LS14pp (≥14) com estratégias de loss/métricas diferentes |
| **Atualização 6x/semana** | Script `retrain_scheduler.py` + cron job |
| **Robustez** | SavedModel + .keras, metadados, fallbacks |
| **Manutenção fácil** | Funções em módulos separados, sem duplicação |
| **Compatibilidade** | Seus outros scripts consomem os mesmos módulos |

---

## 🚀 Próximos passos

1. **Crie `build_datasets.py`** com as funções de dataset.
2. **Remova duplicações** do `train_llm_loteria.py`.
3. **Implemente `retrain_scheduler.py`** com verificação de novos sorteios.
4. **Adicione salvamento de metadados**.
5. **Teste o pipeline completo**:  
   ```bash
   python train_llm_loteria.py --model both --last_n 1000 --out ./models
   python retrain_scheduler.py --models ls15pp ls14pp
   ```

Se quiser, posso gerar os arquivos `build_datasets.py` e `retrain_scheduler.py` para você!
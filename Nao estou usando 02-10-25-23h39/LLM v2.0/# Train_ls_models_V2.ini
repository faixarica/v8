# Train_ls_models_V2


> âœ… **1. Dois modelos distintos**:  
> - **Modelo LS15++**: otimizado para acertar os **15 nÃºmeros exatos** (com loss focada em top-15).  
> - **Modelo LS14++**: otimizado para acertar **pelo menos 14 nÃºmeros** (com Ãªnfase em repetiÃ§Ã£o e recall de positivos).  
>
> âœ… **2. AtualizaÃ§Ã£o contÃ­nua**:  
> - Receber novos sorteios atÃ© **6x/semana** â†’ precisa de **re-treinamento rÃ¡pido, robusto e automatizÃ¡vel**.

---

## ğŸ”§ **Principais problemas atuais**

1. **FunÃ§Ãµes duplicadas**: `fetch_history`, `to_binary`, `build_dataset_*` estÃ£o definidas **dentro do mesmo arquivo**, mas tambÃ©m sÃ£o importadas de `utils_ls_models` e `build_models` â†’ conflito e manutenÃ§Ã£o difÃ­cil.
2. **Modelos LS15 e LS14 bÃ¡sicos nÃ£o sÃ£o usados** â€” vocÃª jÃ¡ tem versÃµes `pp` (plus-plus) mais avanÃ§adas.
3. **Falta de padronizaÃ§Ã£o** no treinamento: LS14pp usa `class_weight`, LS15pp usa `loss customizada + callback de mÃ©tricas`.
4. **NÃ£o hÃ¡ suporte nativo para re-treinamento incremental** (ex: rodar diariamente via cron).
5. **Salvamento apenas em `.keras`** â€” ideal ter **SavedModel tambÃ©m** para compatibilidade.

---

## âœ… **Proposta de melhoria: 5 aÃ§Ãµes prÃ¡ticas**

### **1. Elimine duplicaÃ§Ãµes â€” use um Ãºnico mÃ³dulo de dados**
Remova as funÃ§Ãµes `fetch_history`, `to_binary`, `build_dataset_*` do arquivo principal.  
**Mantenha apenas os imports**:

```python
from utils_ls_models import fetch_history, to_binary
from build_datasets import build_dataset_ls15pp, build_dataset_ls14pp  # crie este mÃ³dulo
from build_models import build_lstm_ls15pp, build_lstm_ls14pp_hybrid
```

> ğŸ’¡ Crie um arquivo `build_datasets.py` com todas as funÃ§Ãµes de construÃ§Ã£o de dataset. Isso evita conflitos e facilita manutenÃ§Ã£o.

---

### **2. Padronize o treinamento com callbacks robustos para AMBOS os modelos**

Use o **mesmo padrÃ£o** para os dois modelos:

- **LS15++**: otimiza **acerto mÃ©dio de 15 nÃºmeros** â†’ use `LoteriaMetricsCallback(k=15)`.
- **LS14++**: otimiza **frequÃªncia de â‰¥14 acertos** â†’ use `LoteriaMetricsCallback(k=14)` + **loss com `pos_weight` alto**.

#### Exemplo de treino padronizado:
```python
def train_model(
    model_name: str,      # "ls15pp" ou "ls14pp"
    last_n=1000,
    window=50,
    epochs=100,
    batch=32,
    out_dir="./models"
):
    # 1. Carregar dados
    if model_name == "ls14pp":
        rows, rep_map = fetch_history(last_n=last_n, include_repeats=True)
        X, y = build_dataset_ls14pp(rows, rep_map, window)
        model = build_lstm_ls14pp_hybrid((window, 25), pos_weight=3.0)
        loss = weighted_bce(pos_weight=3.0)  # ou use class_weight
        k_target = 14
    else:  # ls15pp
        rows = fetch_history(last_n=last_n)
        X, y = build_dataset_ls15pp(rows, window)
        model = build_lstm_ls15pp((window, 25))
        loss = bce_with_topk_proxy(k=15, alpha=1.0)
        k_target = 15

    model.compile(optimizer=Adam(1e-3), loss=loss)

    # 2. Split
    (X_train, y_train), (X_val, y_val) = train_val_split(X, y)

    # 3. Callbacks
    base_name = f"modelo_{model_name}"
    best_loss_path = os.path.join(out_dir, f"{base_name}_bestloss.keras")
    best_hits_path = os.path.join(out_dir, f"{base_name}_besthits.keras")

    callbacks = [
        ModelCheckpoint(best_loss_path, monitor="val_loss", save_best_only=True),
        LoteriaMetricsCallback(
            val_data=(X_val, y_val),
            k=k_target,
            save_best_path=best_hits_path,
            verbose=1
        ),
        EarlyStopping(patience=10, restore_best_weights=True),
        ReduceLROnPlateau(patience=5, factor=0.5)
    ]

    # 4. Treinar
    model.fit(X_train, y_train, validation_data=(X_val, y_val), ...)

    # 5. Salvar em DOIS formatos
    model.save(best_hits_path)  # .keras
    model.export(best_hits_path.replace(".keras", "_saved"))  # SavedModel (Keras 3+)

    return model
```

---

### **3. Adicione suporte a re-treinamento automÃ¡tico (6x/semana)**

Crie um **script separado** ou **funÃ§Ã£o `retrain_if_new_data()`**:

```python
def retrain_if_new_data(model_name: str, min_new_draws=1):
    """
    Verifica se hÃ¡ novos sorteios desde o Ãºltimo treino.
    Se sim, re-treina o modelo.
    """
    last_concurso_db = get_last_concurso_from_db()  # nova funÃ§Ã£o em db_utils
    last_concurso_model = get_last_concurso_from_model_metadata(model_name)  # salve isso no treino!

    if last_concurso_db > last_concurso_model + min_new_draws:
        logging.info(f"Novos sorteios detectados! Re-treinando {model_name}...")
        train_model(model_name, last_n=1500, window=50, out_dir="./models")
    else:
        logging.info("Nenhum novo sorteio relevante. Pulando re-treino.")
```

> ğŸ•’ **Agende com cron (Linux) ou Task Scheduler (Windows)** para rodar **6x/semana**:
> ```bash
> # Ex: rodar Ã s 2h da manhÃ£, seg a sÃ¡b
> 0 2 * * 1-6 cd /seu/projeto && python retrain_scheduler.py --models ls15pp ls14pp
> ```

---

### **4. Salve metadados junto com o modelo**

Ao treinar, salve um arquivo `metadata.json` com:
```json
{
  "model_name": "ls15pp",
  "last_concurso_trained": 3000,
  "last_n": 1500,
  "window": 50,
  "mean_hits_val": 11.2,
  "date_trained": "2024-06-10T10:30:00Z"
}
```

Isso permite:
- Saber **atÃ© que sorteio o modelo foi treinado**.
- Evitar re-treinar sem necessidade.
- Comparar versÃµes.

---

### **5. Mantenha compatibilidade com seus scripts existentes**

Seus outros arquivos (`train_ls_models_v1_and_auto_retrain_updates.py`, `train_ls_models_advanced.py`) devem poder:
- **Carregar os modelos salvos** (`.keras` ou `_saved`).
- **Usar as mesmas funÃ§Ãµes de `utils_ls_models` e `build_datasets`**.

âœ… **SoluÃ§Ã£o**:  
- Mantenha **todos os utilitÃ¡rios em mÃ³dulos separados** (`utils_ls_models.py`, `build_datasets.py`, `build_models.py`).
- Seus scripts de treino **sÃ³ devem conter lÃ³gica de treino**, nÃ£o definiÃ§Ãµes de funÃ§Ãµes.

---

## ğŸ“ Estrutura final recomendada

```
projeto/
â”œâ”€â”€ train_llm_loteria.py          â† sÃ³ treino + CLI
â”œâ”€â”€ retrain_scheduler.py          â† checa novos sorteios e re-treina
â”œâ”€â”€ utils_ls_models.py            â† fetch_history, to_binary
â”œâ”€â”€ build_datasets.py             â† build_dataset_ls15pp, build_dataset_ls14pp
â”œâ”€â”€ build_models.py               â† build_lstm_ls15pp, build_lstm_ls14pp_hybrid
â”œâ”€â”€ db.py                         â† Session
â”œâ”€â”€ models/                       â† modelos salvos (.keras + _saved)
â”‚   â”œâ”€â”€ modelo_ls15pp_besthits.keras
â”‚   â”œâ”€â”€ modelo_ls15pp_besthits_saved/
â”‚   â”œâ”€â”€ modelo_ls14pp_besthits.keras
â”‚   â””â”€â”€ ...
â””â”€â”€ backtest/                     â† para testes histÃ³ricos
```

---

## âœ… BenefÃ­cios dessa abordagem

| BenefÃ­cio | Como Ã© resolvido |
|--------|------------------|
| **Dois modelos distintos** | LS15pp (top-15) e LS14pp (â‰¥14) com estratÃ©gias de loss/mÃ©tricas diferentes |
| **AtualizaÃ§Ã£o 6x/semana** | Script `retrain_scheduler.py` + cron job |
| **Robustez** | SavedModel + .keras, metadados, fallbacks |
| **ManutenÃ§Ã£o fÃ¡cil** | FunÃ§Ãµes em mÃ³dulos separados, sem duplicaÃ§Ã£o |
| **Compatibilidade** | Seus outros scripts consomem os mesmos mÃ³dulos |

---

## ğŸš€ PrÃ³ximos passos

1. **Crie `build_datasets.py`** com as funÃ§Ãµes de dataset.
2. **Remova duplicaÃ§Ãµes** do `train_llm_loteria.py`.
3. **Implemente `retrain_scheduler.py`** com verificaÃ§Ã£o de novos sorteios.
4. **Adicione salvamento de metadados**.
5. **Teste o pipeline completo**:  
   ```bash
   python train_llm_loteria.py --model both --last_n 1000 --out ./models
   python retrain_scheduler.py --models ls15pp ls14pp
   ```

Se quiser, posso gerar os arquivos `build_datasets.py` e `retrain_scheduler.py` para vocÃª!